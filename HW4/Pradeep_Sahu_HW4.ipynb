{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pradeep_Sahu_HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNteeFvNF6pKayylZLbQkYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahupra1357/CPE695AML/blob/main/HW4/Pradeep_Sahu_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6TJV0gtuYKQ"
      },
      "source": [
        "#In this programming problem, you will get familiar with building a neural network using backpropagation. You are supposed to implement the following steps:  \n",
        "# **Step 1**: use our “titanic” dataset in homework 3, and split data in the same way you did in homework 3 – 80% as training and 20% test sets;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qw2A2GucNckY",
        "outputId": "b69b83d8-feae-4963-9002-a318e39a2657"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6e2456d8-a3d0-4854-be57-3fb992d9b788\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6e2456d8-a3d0-4854-be57-3fb992d9b788\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Titanic.csv to Titanic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY_ZZmQGNze5",
        "outputId": "6d7d0f6f-22fa-4eea-fe31-8f42e2ff8232"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  Titanic.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnbl9R9bNzcl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pydotplus\n",
        "from IPython.display import Image "
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBWbllmCNzZo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "3cc18fef-2d2d-4894-df2d-ff24d849b514"
      },
      "source": [
        "pd.set_option('mode.chained_assignment', None)\n",
        "data = pd.read_csv(\"Titanic.csv\")\n",
        "df = data.drop(data.columns[[0]],axis=1)\n",
        "df.head()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>ticket</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>home.dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1st</td>\n",
              "      <td>1</td>\n",
              "      <td>Allen, Miss. Elisabeth Walton</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24160</td>\n",
              "      <td>211.337494</td>\n",
              "      <td>B5</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>St Louis, MO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1st</td>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.550003</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1st</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Miss. Helen Loraine</td>\n",
              "      <td>female</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.550003</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1st</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mr. Hudson Joshua Crei</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.550003</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1st</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessi</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.550003</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  pclass  survived  ...   body                        home.dest\n",
              "0    1st         1  ...    NaN                     St Louis, MO\n",
              "1    1st         1  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "2    1st         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "3    1st         0  ...  135.0  Montreal, PQ / Chesterville, ON\n",
              "4    1st         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbsmYIzCNzWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a66809e-6df6-41bc-8715-8918afd0e0b4"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pclass          0\n",
              "survived        0\n",
              "name            0\n",
              "sex             0\n",
              "age           263\n",
              "sibsp           0\n",
              "parch           0\n",
              "ticket          0\n",
              "fare            1\n",
              "cabin        1014\n",
              "embarked        2\n",
              "boat          823\n",
              "body         1188\n",
              "home.dest     564\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHQVUhZ4NzTu"
      },
      "source": [
        "df['age'].fillna(value=df['age'].mean(), inplace=True)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-aylIQlKOBw",
        "outputId": "3a5120e0-1aa7-4cc6-9410-f09614157994"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pclass          0\n",
              "survived        0\n",
              "name            0\n",
              "sex             0\n",
              "age             0\n",
              "sibsp           0\n",
              "parch           0\n",
              "ticket          0\n",
              "fare            1\n",
              "cabin        1014\n",
              "embarked        2\n",
              "boat          823\n",
              "body         1188\n",
              "home.dest     564\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPkbaMRPJive"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "df[['age']] = sc.fit_transform(df[['age']])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBlKk-_ENzNt"
      },
      "source": [
        "X = df[[\"pclass\",\"sex\",\"age\",\"sibsp\"]]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W4c3XnJNzKy"
      },
      "source": [
        "Y = df[[\"survived\"]]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3gEW7eINzGt"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "X['pclass'] = le.fit_transform(X['pclass'])\n",
        "\n",
        "X['sex'] = le.fit_transform(X['sex'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "1yN-vyo2JDBX",
        "outputId": "5697c0dc-16f9-4ee4-f813-c2784d2d8e99"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.068420</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.249092</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-2.164974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.009230</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.379021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  sex       age  sibsp\n",
              "0       0    0 -0.068420      0\n",
              "1       0    1 -2.249092      1\n",
              "2       0    0 -2.164974      1\n",
              "3       0    1  0.009230      1\n",
              "4       0    0 -0.379021      1"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLtNRxXoNzDG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Nr4zN1qFon"
      },
      "source": [
        "**Step 2**: Fit a neural network using independent variables ‘pclass + sex + age + sibsp’ and dependent variable ‘survived’. Fill in n/a attributes with the average of the same attributes from other training examples. Use 2 hidden layers and set the activation functions for both the hidden and output layer to be the sigmoid function. Set “solver” parameter as either SGD (stochastic gradient descend) or Adam (similar to SGD but optimized performance with mini batches). You can adjust parameter “alpha” for regularization (to control overfitting) and other parameters such as “learning rate” and “momentum” as needed.\n",
        "\n",
        "# **Option 1**: use scikit-learn library;"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIwAiHUkKpX6"
      },
      "source": [
        "#Importing MLPClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "#Initializing the MLPClassifier\n",
        "classifier = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMlYTwKeKpUY",
        "outputId": "f13a21fe-d3e6-4857-ccde-2146c07524d3"
      },
      "source": [
        "#Fitting the training data to the network\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(150, 100, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=1, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVy_fVMmKpQ_"
      },
      "source": [
        "#Predicting y for X_test\n",
        "y_pred = classifier.predict(X_test)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzfK6q22KpK6"
      },
      "source": [
        "#Importing Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#Comparing the predictions against the actual observations in y_test\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1_9gZRVmAhU",
        "outputId": "ebb58b44-940b-4aba-cef6-9bb38e275e14"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,plot_confusion_matrix\n",
        "print(\"Testing Accuracy:{:.5f}\".format(classifier.score(X_test,y_test)))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy:0.75573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLUKOI3VqSih"
      },
      "source": [
        "**Step 3**: Check the performance of the model with out-of- sample accuracy, defined as\n",
        "out-of-sample percent survivors correctly predicted (on test set)\n",
        "out-of-sample percent fatalities correctly predicted (on test set)\n",
        "Please try two different network structures (i.e., number of neurons at each hidden layer) and show their respective accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "rDZfUjZrKpBu",
        "outputId": "8d408661-ffd9-4c2b-f3dc-81eecf0c9ab4"
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "print('Percent Survivors Correctly Predicted:\\t', 100*(tp / (tp + fn)), '%')\n",
        "print('Percent Fatalities Correctly Predicted:\\t', 100*(tn / (tn + fp)), '%')\n",
        "print('Overall Accuracy:\\t\\t', 100*accuracy_score(y_test,y_pred), '%\\n')\n",
        "plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.Blues,  display_labels = ['Did Not Survive', 'Survived'],values_format='d')\n",
        "plt.show()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percent Survivors Correctly Predicted:\t 50.0 %\n",
            "Percent Fatalities Correctly Predicted:\t 96.52777777777779 %\n",
            "Overall Accuracy:\t\t 75.57251908396947 %\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSW7ogh8qzBW"
      },
      "source": [
        "# **Option 2** (bonus: 2 points): implement backpropagation yourself"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9KqZ-MPS1kn"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CBz6EIHS1hv"
      },
      "source": [
        "def sigmoid(x):\n",
        "    s = 1/(1+np.exp(-x))\n",
        "    return s"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk79wFVYS1fM"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "\n",
        "    W1 = parameters[\"W1\"]\n",
        "    b1 = parameters[\"b1\"]\n",
        "    W2 = parameters[\"W2\"]\n",
        "    b2 = parameters[\"b2\"]\n",
        "    W3 = parameters[\"W3\"]\n",
        "    b3 = parameters[\"b3\"]\n",
        "    \n",
        "    \n",
        "    # LINEAR -> SIGMOID -> LINEAR -> SIGMOID -> LINEAR -> SIGMOID\n",
        "    z1 = np.dot(W1, X) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(W2, a1) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "    z3 = np.dot(W3, a2) + b3\n",
        "    a3 = sigmoid(z3)\n",
        "    \n",
        "    cache = (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3)\n",
        "    return a3, cache"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1a5puavS1cU"
      },
      "source": [
        "def backward_propagation(X, Y, cache):\n",
        "\n",
        "    m = X.shape[1]\n",
        "    (z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3) = cache\n",
        "    \n",
        "    dz3 = 1./m * (a3 - Y)\n",
        "    print(\"dz23 shape \"+str(dz3.shape))\n",
        "    dW3 = np.dot(dz3, a2.T)\n",
        "    db3 = np.sum(dz3, axis=1)\n",
        "    print(\"db3 shape XXXX \"+str(db3))\n",
        "\n",
        "    da2 = np.dot(W3.T, dz3)\n",
        "    dz2 = np.multiply(da2, np.int64(a2 > 0))\n",
        "    dW2 = np.dot(dz2, a1.T)\n",
        "    db2 = np.sum(dz2, axis=1)\n",
        "    \n",
        "    da1 = np.dot(W2.T, dz2)\n",
        "    dz1 = np.multiply(da1, np.int64(a1 > 0))\n",
        "    dW1 = np.dot(dz1, X.T)\n",
        "    db1 = np.sum(dz1, axis=1)\n",
        "    \n",
        "    gradients = {\"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n",
        "                 \"da2\": da2, \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
        "                 \"da1\": da1, \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
        "    \n",
        "    return gradients"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqtxZm-JS1Zs"
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    \n",
        "    L = len(parameters) // 2 # number of layers in the neural networks\n",
        "\n",
        "    # Update rule for each parameter\n",
        "    for k in range(L):\n",
        "        parameters[\"W\" + str(k+1)] = parameters[\"W\" + str(k+1)] - learning_rate * grads[\"dW\" + str(k+1)]\n",
        "        print(\"Update yyy = \"+str('W' + str(k+1))+\" = \"+str(parameters['W' + str(k+1)].shape))\n",
        "        print(grads[\"db\" + str(k+1)].T)\n",
        "        print(parameters[\"b\" + str(k+1)].shape)\n",
        "        print(parameters[\"b\" + str(k+1)] - learning_rate * grads[\"db\" + str(k+1)])\n",
        "        parameters[\"b\" + str(k+1)] = parameters[\"b\" + str(k+1)].T - learning_rate * grads[\"db\" + str(k+1)]\n",
        "        print(parameters[\"b\" + str(k+1)])\n",
        "        print(\"Update = \"+str('b' + str(k+1))+\" = \"+str(parameters['b' + str(k+1)].shape))\n",
        "    print(parameters)\n",
        "    return parameters"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp77UkImS1W1"
      },
      "source": [
        "def compute_loss(a3, Y):\n",
        "    m = Y.shape[1]\n",
        "    logprobs = np.multiply(-np.log(a3),Y) + np.multiply(-np.log(1 - a3), 1 - Y)\n",
        "    loss = 1./m * np.nansum(logprobs)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O29Yh2RVtGH"
      },
      "source": [
        "def predict(X, y, parameters):\n",
        "  \n",
        "    m = X.shape[1]\n",
        "    p = np.zeros((1,m), dtype = np.int)\n",
        "    \n",
        "    # Forward propagation\n",
        "    a3, caches = forward_propagation(X, parameters)\n",
        "    \n",
        "    # convert probas to 0/1 predictions\n",
        "    for i in range(0, a3.shape[1]):\n",
        "        if a3[0,i] > 0.5:\n",
        "            p[0,i] = 1\n",
        "        else:\n",
        "            p[0,i] = 0\n",
        "\n",
        "    # print results\n",
        "    print(\"Accuracy: \"  + str(np.mean((p[0,:] == y[0,:]))))\n",
        "    \n",
        "    return p"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4OJ1hkQZOER"
      },
      "source": [
        "def initialize_parameters_random(layers_dims):\n",
        "    np.random.seed(3)               \n",
        "    parameters = {}\n",
        "    L = len(layers_dims)            # integer representing the number of layers\n",
        "    \n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layers_dims[l], layers_dims[l-1])*10\n",
        "        print(\"Initialize = \"+str('W' + str(l))+\" = \"+str(parameters['W' + str(l)].shape))\n",
        "        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))\n",
        "        print(\"Initialize = \"+str('b' + str(l))+\" = \"+str(parameters['b' + str(l)].shape))\n",
        "\n",
        "    return parameters"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVulU9VIS1T_"
      },
      "source": [
        "def model(X, Y, learning_rate = 0.01, num_iterations = 15000, print_cost = True):\n",
        "    grads = {}\n",
        "    costs = [] \n",
        "    print(X.shape)\n",
        "    m = X.shape[1] \n",
        "    layers_dims = [X.shape[0], 10, 5, 1]\n",
        "    print(layers_dims)\n",
        "    parameters = initialize_parameters_random(layers_dims)\n",
        "    # Loop (gradient descent)\n",
        "\n",
        "    for i in range(0, num_iterations):\n",
        "\n",
        "        # Forward propagation: LINEAR -> SIGMOID -> LINEAR -> SIGMOID -> LINEAR -> SIGMOID.\n",
        "        a3, cache = forward_propagation(X, parameters)\n",
        "        \n",
        "        # Loss\n",
        "        cost = compute_loss(a3, Y)\n",
        "\n",
        "        # Backward propagation.\n",
        "        grads = backward_propagation(X, Y, cache)\n",
        "        \n",
        "        # Update parameters.\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "        print(parameters.shape)\n",
        "        # Print the loss every 1000 iterations\n",
        "        print(i)\n",
        "        if print_cost and i % 1000 == 0:\n",
        "            print(\"Cost after iteration {}: {}\".format(i, cost))\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the loss\n",
        "    plt.plot(costs)\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZXh0hndnbsM"
      },
      "source": [
        "X2_train = X_train.T\n",
        "y2_train = y_train.T\n",
        "X2_test = X_test.T\n",
        "y2_test = y_train.T"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VTm2icHCU6BW",
        "outputId": "8c769247-8220-4456-aa43-0d465e9c8c19"
      },
      "source": [
        "parameters = model(X2_train, y2_train)\n",
        "print (\"On the train set:\")\n",
        "predictions_train = predict(X2_train, y2_train, parameters)\n",
        "print (\"On the test set:\")\n",
        "predictions_test = predict(X2_test, y2_test, parameters)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1047)\n",
            "[4, 10, 5, 1]\n",
            "Initialize = W1 = (10, 4)\n",
            "Initialize = b1 = (10, 1)\n",
            "Initialize = W2 = (5, 10)\n",
            "Initialize = b2 = (5, 1)\n",
            "Initialize = W3 = (1, 5)\n",
            "Initialize = b3 = (1, 1)\n",
            "dz23 shape (1, 1047)\n",
            "db3 shape XXXX survived   -0.339447\n",
            "dtype: float64\n",
            "Update XXX = W1 = (10, 4)\n",
            "[  5.73394872  64.52238908  19.80321567   3.46794446 -11.24832136\n",
            " -12.38186212  -6.42975616 -87.22961242 -80.41149907 -12.52953533]\n",
            "(10, 1)\n",
            "[[-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]\n",
            " [-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]]\n",
            "[[-0.05733949 -0.64522389 -0.19803216 -0.03467944  0.11248321  0.12381862\n",
            "   0.06429756  0.87229612  0.80411499  0.12529535]]\n",
            "Update = b1 = (1, 10)\n",
            "Update XXX = W2 = (5, 10)\n",
            "[ 2.00640098  1.75296495  3.25868137 -1.28071859  1.95083237]\n",
            "(5, 1)\n",
            "[[-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]\n",
            " [-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]\n",
            " [-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]\n",
            " [-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]\n",
            " [-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]]\n",
            "[[-0.02006401 -0.01752965 -0.03258681  0.01280719 -0.01950832]]\n",
            "Update = b2 = (1, 5)\n",
            "Update XXX = W3 = (1, 5)\n",
            "survived   -0.339447\n",
            "dtype: float64\n",
            "(1, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-251-740817ec56c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"On the train set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredictions_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"On the test set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-175-4f02cc0855fc>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X, Y, learning_rate, num_iterations, print_cost)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Update parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Print the loss every 1000 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-244-646c7ee4abd6>\u001b[0m in \u001b[0;36mupdate_parameters\u001b[0;34m(parameters, grads, learning_rate)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[0;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         result = ops.maybe_dispatch_ufunc_to_dunder_op(\n\u001b[0;32m--> 683\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         )\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/ops/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   2768\u001b[0m         \u001b[0;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m         \u001b[0;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Data must be 1-dimensional"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5H3aEC6cjCh"
      },
      "source": [
        "#Importing Confusion Matrix\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,plot_confusion_matrix\n",
        "#Comparing the predictions against the actual observations in y_test\n",
        "cm = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq4P_-Xzci_5"
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(y_test, predictions_test).ravel()\n",
        "print('Percent Survivors Correctly Predicted:\\t', 100*(tp / (tp + fn)), '%')\n",
        "print('Percent Fatalities Correctly Predicted:\\t', 100*(tn / (tn + fp)), '%')\n",
        "print('Overall Accuracy:\\t\\t', 100*accuracy_score(y_test,predictions_test), '%\\n')\n",
        "plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.Blues,  display_labels = ['Did Not Survive', 'Survived'],values_format='d')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}